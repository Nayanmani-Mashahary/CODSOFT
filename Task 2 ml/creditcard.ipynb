{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTk33CLdDgyM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Dataset path\n",
        "data_path = \"/content/drive/MyDrive/credit card fraud\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_path = '/content/drive/MyDrive/credit card fraud'\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(data_path, 'fraudTrain.csv'))\n",
        "test_df = pd.read_csv(os.path.join(data_path, 'fraudTest.csv'))\n",
        "\n",
        "print(f\"Loaded datasets\\nTrain shape: {train_df.shape}\\nTest shape: {test_df.shape}\\n\")\n",
        "print(\"Train columns:\", train_df.columns.tolist())\n",
        "\n",
        "print(\"\\nTrain sample:\")\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MaxnfegGvFW",
        "outputId": "b865a956-8c21-4739-ccb8-200eba91cde4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded datasets\n",
            "Train shape: (1296675, 23)\n",
            "Test shape: (555719, 23)\n",
            "\n",
            "Train columns: ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n",
            "\n",
            "Train sample:\n",
            "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
            "0           0   2019-01-01 00:00:18  2703186189652095   \n",
            "1           1   2019-01-01 00:00:44      630423337322   \n",
            "2           2   2019-01-01 00:00:51    38859492057661   \n",
            "3           3   2019-01-01 00:01:16  3534093764340240   \n",
            "4           4   2019-01-01 00:03:06   375534208663984   \n",
            "\n",
            "                             merchant       category     amt      first  \\\n",
            "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
            "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
            "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
            "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
            "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
            "\n",
            "      last gender                        street  ...      lat      long  \\\n",
            "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
            "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
            "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
            "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
            "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
            "\n",
            "   city_pop                                job         dob  \\\n",
            "0      3495          Psychologist, counselling  1988-03-09   \n",
            "1       149  Special educational needs teacher  1978-06-21   \n",
            "2      4154        Nature conservation officer  1962-01-19   \n",
            "3      1939                    Patent attorney  1967-01-12   \n",
            "4        99     Dance movement psychotherapist  1986-03-28   \n",
            "\n",
            "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
            "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
            "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
            "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
            "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
            "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
            "\n",
            "   is_fraud  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "drop_cols = ['Unnamed: 0', 'cc_num', 'first', 'last', 'street', 'city', 'state', 'zip', 'job', 'dob', 'trans_num']\n",
        "train_df = train_df.drop(columns=drop_cols)\n",
        "test_df = test_df.drop(columns=drop_cols)\n",
        "\n",
        "for df in [train_df, test_df]:\n",
        "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "    df['hour'] = df['trans_date_trans_time'].dt.hour\n",
        "    df['day'] = df['trans_date_trans_time'].dt.day\n",
        "    df['weekday'] = df['trans_date_trans_time'].dt.weekday\n",
        "    df['month'] = df['trans_date_trans_time'].dt.month\n",
        "    df.drop(columns=['trans_date_trans_time'], inplace=True)\n",
        "\n",
        "categorical_cols = ['merchant', 'category', 'gender']\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
        "    test_df[col] = le.transform(test_df[col].astype(str))\n",
        "\n",
        "print(\"Preprocessing done.\\nTrain sample:\")\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzr1STf3G-VC",
        "outputId": "2d00aa70-3c29-4869-f975-b4060bcd7253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing done.\n",
            "Train sample:\n",
            "   merchant  category     amt  gender      lat      long  city_pop  \\\n",
            "0       514         8    4.97       0  36.0788  -81.1781      3495   \n",
            "1       241         4  107.23       0  48.8878 -118.2105       149   \n",
            "2       390         0  220.11       1  42.1808 -112.2620      4154   \n",
            "3       360         2   45.00       1  46.2306 -112.1138      1939   \n",
            "4       297         9   41.96       1  38.4207  -79.4629        99   \n",
            "\n",
            "    unix_time  merch_lat  merch_long  is_fraud  hour  day  weekday  month  \n",
            "0  1325376018  36.011293  -82.048315         0     0    1        1      1  \n",
            "1  1325376044  49.159047 -118.186462         0     0    1        1      1  \n",
            "2  1325376051  43.150704 -112.154481         0     0    1        1      1  \n",
            "3  1325376076  47.034331 -112.561071         0     0    1        1      1  \n",
            "4  1325376186  38.674999  -78.632459         0     0    1        1      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(columns=['is_fraud'])\n",
        "y_train = train_df['is_fraud']\n",
        "\n",
        "X_test = test_df.drop(columns=['is_fraud'])\n",
        "y_test = test_df['is_fraud']\n",
        "\n",
        "print(f\"Features and target split.\\nX_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q99-PUivJFQp",
        "outputId": "5868758e-78a2-4e44-e2c2-fcaf5b67cf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features and target split.\n",
            "X_train shape: (1296675, 14), y_train shape: (1296675,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "scaler_path = os.path.join(data_path, 'scaler.pkl')\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f\"Scaling done. Scaler saved to {scaler_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVs-6aelJahB",
        "outputId": "3abe06ea-282c-4072-8225-02732a6a5025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaling done. Scaler saved to /content/drive/MyDrive/credit card fraud/scaler.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "log_reg_path = os.path.join(data_path, 'logistic_regression_model.pkl')\n",
        "joblib.dump(log_reg, log_reg_path)\n",
        "print(f\"Logistic Regression trained and saved to {log_reg_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3nqhyNNJgou",
        "outputId": "f6dde06e-d6d0-4405-cf35-472aa5c111fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression trained and saved to /content/drive/MyDrive/credit card fraud/logistic_regression_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "dt_model_path = os.path.join(data_path, 'decision_tree_model.pkl')\n",
        "joblib.dump(dt_model, dt_model_path)\n",
        "print(f\" Decision Tree trained and saved to {dt_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0pWZgpBJ_hx",
        "outputId": "3f52f39f-0c70-4b93-8db2-3b7ebc429215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Decision Tree trained and saved to /content/drive/MyDrive/credit card fraud/decision_tree_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "rf_model_path = os.path.join(data_path, 'random_forest_model.pkl')\n",
        "joblib.dump(rf_model, rf_model_path)\n",
        "print(f\"Random Forest trained and saved to {rf_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCFHzycJKSvk",
        "outputId": "cf928bbe-9b24-4466-d1a8-74f3b1cae484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest trained and saved to /content/drive/MyDrive/credit card fraud/random_forest_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': log_reg,\n",
        "    'Decision Tree': dt_model,\n",
        "    'Random Forest': rf_model\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name == 'Logistic Regression':\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igr2bgfbLfBp",
        "outputId": "56f61ee7-a9c8-4b83-d6de-531bd306f2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy:  0.9955\n",
            "Precision: 0.0000\n",
            "Recall:    0.0000\n",
            "F1 Score:  0.0000\n",
            "Confusion Matrix:\n",
            "[[553238    336]\n",
            " [  2145      0]]\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy:  0.9951\n",
            "Precision: 0.4202\n",
            "Recall:    0.7166\n",
            "F1 Score:  0.5297\n",
            "Confusion Matrix:\n",
            "[[551453   2121]\n",
            " [   608   1537]]\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy:  0.9982\n",
            "Precision: 0.9281\n",
            "Recall:    0.5837\n",
            "F1 Score:  0.7167\n",
            "Confusion Matrix:\n",
            "[[553477     97]\n",
            " [   893   1252]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "metrics_list = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name == 'Logistic Regression':\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    metrics_list.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': prec,\n",
        "        'Recall': rec,\n",
        "        'F1 Score': f1,\n",
        "        'Confusion Matrix': cm.tolist()\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "metrics_path = os.path.join(data_path, 'model_metrics.csv')\n",
        "metrics_df.to_csv(metrics_path, index=False)\n",
        "\n",
        "print(f\"Metrics saved to {metrics_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1GhN3bfMy09",
        "outputId": "8a61d815-2d80-43c8-d903-a543f850eedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics saved to /content/drive/MyDrive/credit card fraud/model_metrics.csv\n"
          ]
        }
      ]
    }
  ]
}